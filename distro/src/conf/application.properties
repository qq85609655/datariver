#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#########  Graph Database Configs  #########
# Graph Storage
atlas.graph.storage.backend=berkeleyje
atlas.graph.storage.directory=${sys:atlas.home}/data/berkley
atlas.graph.storage.transactions=false


#####################################################
######## for dtdream atlas storage backend
######## 使用cassandra作为存储时，将下面几行注释删除，并将上面的berkeleyje注释掉
# atlas.graph.storage.backend=cassandra
# atlas.graph.storage.hostname=mdm21
# atlas.graph.storage.port=9160
# atlas.graph.storage.cassandra.keyspace=titan
# atlas.graph.storage.batch-loading=false
#####################################################

# cassandrathrift, 9160, 7000, 7199,


# index.search.backend=elasticsearch
# index.search.hostname=100.100.101.1,100.100.101.2
# index.search.elasticsearch.client-only=true
#####################################################


#Hbase as stoarge backend
#hbase
#For standalone mode , specify localhost
#for distributed mode, specify zookeeper quorum here - For more information refer http://s3.thinkaurelius.com/docs/titan/current/hbase.html#_remote_server_mode_2
#atlas.graph.storage.hostname=localhost
#atlas.graph.storage.hbase.regions-per-server=1
#atlas.graph.storage.lock.wait-time=10000

#Solr
#atlas.graph.index.search.backend=solr

# Solr cloud mode properties
#atlas.graph.index.search.solr.mode=cloud
#atlas.graph.index.search.solr.zookeeper-url=localhost:2181

#Solr http mode properties
#atlas.graph.index.search.solr.mode=http
#atlas.graph.index.search.solr.http-urls=http://localhost:8983/solr

# Graph Search Index
#ElasticSearch
# 后端搜索引擎的配置，atlas.graph是配置前缀，去掉前缀后和后端存储引擎的配置一起用于Titan的配置
atlas.graph.index.search.backend=elasticsearch
atlas.graph.index.search.directory=${sys:atlas.home}/data/es
atlas.graph.index.search.elasticsearch.client-only=false
atlas.graph.index.search.elasticsearch.local-mode=true
atlas.graph.index.search.elasticsearch.create.sleep=2000


##################################
##### 缓存机制
# atlas.graph.cache.db-cache = true
# atlas.graph.cache.db-cache-clean-wait = 20
# atlas.graph.cache.db-cache-time = 180000
# atlas.graph.cache.db-cache-size = 0.5


#########  Notification Configs  #########
atlas.notification.embedded=true
atlas.kafka.data=${sys:atlas.home}/data/kafka
atlas.kafka.zookeeper.connect=localhost:9026
atlas.kafka.bootstrap.servers=localhost:9027
atlas.kafka.zookeeper.session.timeout.ms=4000
atlas.kafka.zookeeper.sync.time.ms=20
atlas.kafka.auto.commit.interval.ms=1000
atlas.kafka.hook.group.id=atlas


#########  Hive Lineage Configs  #########
# This models reflects the base super types for Data and Process
#atlas.lineage.hive.table.type.name=DataSet
#atlas.lineage.hive.process.type.name=Process
#atlas.lineage.hive.process.inputs.name=inputs
#atlas.lineage.hive.process.outputs.name=outputs

#########  DXT Lineage Configs  #########
# This models reflects the base super types for Data and Process
#atlas.lineage.table.type.name=DataTable
#atlas.lineage.db.type.name=DataContainer
#atlas.lineage.task.process.type.name=LineageTaskProcessInfo
#atlas.lineage.step.process.type.name=LineageStepProcessInfo
#atlas.lineage.workflow.process.type.name=LineageWorkflowProcessInfo
#atlas.lineage.process.inputs.name=inputs
#atlas.lineage.process.outputs.name=outputs
#atlas.lineage.process.inputdbs.name=inputDbs
#atlas.lineage.process.outputdbs.name=outputDbs

#atlas.lineage.step.type.name=ETLStep
#atlas.lineage.action.type.name=WorkflowAction
#atlas.lineage.action.type.task=ETLTask
#atlas.lineage.abstractProcess.type.name=AbstractProcess
#atlas.lineage.sequence.type.name=ETLStepSequence
#atlas.lineage.sequence.preceding.name=preceding
#atlas.lineage.sequence.succeeding.name=succeeding

#atlas.lineage.field.type.name=DataField
#atlas.lineage.task.map.type.name=LineageTaskFieldMap
#atlas.lineage.step.map.type.name=LineageStepFieldMap
#atlas.lineage.map.source.name=sourceField
#atlas.lineage.map.target.name=targetField

## Schema
atlas.lineage.hive.table.schema.query.hive_table=hive_table where name='%s'\, columns
atlas.lineage.hive.table.schema.query.Table=Table where name='%s'\, columns

atlas.lineage.table.schema.query.DataTable=DataTable where qualifiedName='%s'\, fields

## Server port configuration
#atlas.server.http.port=21000
#atlas.server.https.port=21443

#########  Security Properties  #########

# SSL config
atlas.enableTLS=false

atlas.rest.address=http://localhost:21000